{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMcFAVnhv6dBMd6JNAWzEeO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Uyq75dn2Mk6x"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/sjchoi86/upstage-basic-deeplearning/blob/main/notebook/lstm.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/sjchoi86/upstage-basic-deeplearning/blob/main/notebook/lstm.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View Source</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"PJwtTg9a11du"},"source":["# Classification with LSTM"]},{"cell_type":"code","metadata":{"id":"tepz70nH1wwO"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","print (\"PyTorch version:[%s].\"%(torch.__version__))\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print (\"device:[%s].\"%(device))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjSfbrHz2NbN"},"source":["### Dataset and Loader"]},{"cell_type":"code","metadata":{"id":"_apH6GPI2Adq"},"source":["from torchvision import datasets,transforms\n","mnist_train = datasets.MNIST(root='./data/',train=True,transform=transforms.ToTensor(),download=True)\n","mnist_test = datasets.MNIST(root='./data/',train=False,transform=transforms.ToTensor(),download=True)\n","BATCH_SIZE = 256\n","train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n","test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n","print (\"Done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10evD4Jg2bQ4"},"source":["### Define Model"]},{"cell_type":"code","metadata":{"id":"QoISvH_O2OWO"},"source":["class RecurrentNeuralNetworkClass(nn.Module):\n","    def __init__(self,name='rnn',xdim=28,hdim=256,ydim=10,n_layer=3):\n","        super(RecurrentNeuralNetworkClass,self).__init__()\n","        self.name = name\n","        self.xdim = xdim\n","        self.hdim = hdim\n","        self.ydim = ydim\n","        self.n_layer = n_layer # K\n","\n","        self.rnn = nn.LSTM(\n","            input_size=self.xdim,hidden_size=self.hdim,num_layers=self.n_layer,batch_first=True)\n","        self.lin = nn.Linear(self.hdim,self.ydim)\n","\n","    def forward(self,x):\n","        # Set initial hidden and cell states \n","        h0 = torch.zeros(\n","            # FILL IN HERE\n","        ).to(device)\n","        c0 = torch.zeros(\n","            # FILL IN HERE\n","        ).to(device)\n","        # RNN\n","        rnn_out,(hn,cn) = self.rnn(x, (h0,c0)) \n","        # x:[N x L x Q] => rnn_out:[N x L x D]\n","        # Linear\n","        out = self.lin(\n","            # FILL IN HERE\n","            ).view([-1,self.ydim]) \n","        return out \n","\n","R = RecurrentNeuralNetworkClass(\n","    name='rnn',xdim=28,hdim=256,ydim=10,n_layer=2).to(device)\n","loss = nn.CrossEntropyLoss()\n","optm = optim.Adam(R.parameters(),lr=1e-3)\n","print (\"Done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"liD6DC7KANYR"},"source":["### Check How LSTM Works\n","- `N`: number of batches\n","- `L`: sequence lengh\n","- `Q`: input dim\n","- `K`: number of layers\n","- `D`: LSTM feature dimension\n","\n","` Y,(hn,cn) = LSTM(X) `\n","\n","- `X`: [N x L x Q] - `N` input sequnce of length `L` with `Q` dim. \n","- `Y`: [N x L x D] - `N` output sequnce of length `L` with `D` feature dim.\n","- `hn`: [K x N x D] - `K` (per each layer) of `N` final hidden state with  `D` feature dim. \n","- `cn`: [K x N x D] - `K` (per each layer) of `N` final hidden state with  `D` cell dim. "]},{"cell_type":"code","metadata":{"id":"byX3ViAwARpt"},"source":["np.set_printoptions(precision=3)\n","torch.set_printoptions(precision=3)\n","x_numpy = np.random.rand(2,20,28) # [N x L x Q]\n","x_torch = torch.from_numpy(x_numpy).float().to(device)\n","rnn_out,(hn,cn) = R.rnn(x_torch) # forward path\n","\n","print (\"rnn_out:\",rnn_out.shape) # [N x L x D]\n","print (\"Hidden State hn:\",hn.shape) # [K x N x D]\n","print (\"Cell States cn:\",cn.shape) # [K x N x D]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuBUgRKD5vTx"},"source":["### Check parameters"]},{"cell_type":"code","metadata":{"id":"raw5y-vn4rWa"},"source":["np.set_printoptions(precision=3)\n","n_param = 0\n","for p_idx,(param_name,param) in enumerate(R.named_parameters()):\n","    if param.requires_grad:\n","        param_numpy = param.detach().cpu().numpy() # to numpy array \n","        n_param += len(param_numpy.reshape(-1))\n","        print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n","        print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n","print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J6rRmikB8dxU"},"source":["### Simple Forward Path "]},{"cell_type":"code","metadata":{"id":"DBdN6qoO8dah"},"source":["np.set_printoptions(precision=3)\n","torch.set_printoptions(precision=3)\n","x_numpy = np.random.rand(3,10,28) # [N x L x Q]\n","x_torch = torch.from_numpy(x_numpy).float().to(device)\n","y_torch = R.forward(x_torch) # [N x 1 x R] where R is the output dim.\n","y_numpy = y_torch.detach().cpu().numpy() # torch tensor to numpy array\n","# print (\"x_torch:\\n\",x_torch)\n","# print (\"y_torch:\\n\",y_torch)\n","print (\"x_numpy %s\"%(x_numpy.shape,))\n","print (\"y_numpy %s\"%(y_numpy.shape,))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zi5cIbKG6X3w"},"source":["### Evaluation Function"]},{"cell_type":"code","metadata":{"id":"-STglZMq5xKk"},"source":["def func_eval(model,data_iter,device):\n","    with torch.no_grad():\n","        n_total,n_correct = 0,0\n","        model.eval() # evaluate (affects DropOut and BN)\n","        for batch_in,batch_out in data_iter:\n","            y_trgt = batch_out.to(device)\n","            model_pred = model.forward(batch_in.view(-1,28,28).to(device))\n","            _,y_pred = torch.max(model_pred,1)\n","            n_correct += (y_pred==y_trgt).sum().item()\n","            n_total += batch_in.size(0)\n","        val_accr = (n_correct/n_total)\n","        model.train() # back to train mode \n","    return val_accr\n","print (\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pA-3-qPZ6h5u"},"source":["### Initial Evaluation"]},{"cell_type":"code","metadata":{"id":"qGbdjuhB6Z7U"},"source":["train_accr = func_eval(R,train_iter,device)\n","test_accr = func_eval(R,test_iter,device)\n","print (\"train_accr:[%.3f] test_accr:[%.3f].\"%(train_accr,test_accr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PWywAU1-Lm0G"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"sp11_Glg6k7e"},"source":["print (\"Start training.\")\n","R.train() # to train mode \n","EPOCHS,print_every = 5,1\n","for epoch in range(EPOCHS):\n","    loss_val_sum = 0\n","    for batch_in,batch_out in train_iter:\n","        # Forward path\n","        y_pred = R.forward(batch_in.view(-1,28,28).to(device))\n","        loss_out = loss(y_pred,batch_out.to(device))\n","        # Update\n","        optm.zero_grad() # reset gradient \n","        loss_out.backward() # backpropagate\n","        optm.step() # optimizer update\n","        loss_val_sum += loss_out\n","    loss_val_avg = loss_val_sum/len(train_iter)\n","    # Print\n","    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n","        train_accr = func_eval(R,train_iter,device)\n","        test_accr = func_eval(R,test_iter,device)\n","        print (\"epoch:[%d] loss:[%.3f] train_accr:[%.3f] test_accr:[%.3f].\"%\n","               (epoch,loss_val_avg,train_accr,test_accr))\n","print (\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4JDDHhJtR1aR"},"source":["### Test"]},{"cell_type":"code","metadata":{"id":"HrcOUIBrmNf-"},"source":["n_sample = 25\n","sample_indices = np.random.choice(len(mnist_test.targets),n_sample,replace=False)\n","test_x = mnist_test.data[sample_indices]\n","test_y = mnist_test.targets[sample_indices]\n","with torch.no_grad():\n","    R.eval() # to evaluation mode \n","    y_pred = R.forward(test_x.view(-1,28,28).type(torch.float).to(device)/255.)\n","y_pred = y_pred.argmax(axis=1)\n","plt.figure(figsize=(10,10))\n","for idx in range(n_sample):\n","    plt.subplot(5, 5, idx+1)\n","    plt.imshow(test_x[idx], cmap='gray')\n","    plt.axis('off')\n","    plt.title(\"Pred:%d, Label:%d\"%(y_pred[idx],test_y[idx]))\n","plt.show()\n","print (\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkVkpsQymNuC"},"source":[""],"execution_count":null,"outputs":[]}]}